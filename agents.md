ü§ñ agents.md: Trading Bot Signal Agents & Future AI Integration
üß† Core Philosophy

This bot is designed with CPU-first architecture, leveraging pure price-based analysis to generate actionable trading signals across multiple timeframes (1m, 5m, 15m).
All features, scores, and weights are computed from Pyth price feed only ‚Äî without requiring order book snapshots, vault deltas, or transaction logs.

This structure ensures:

    Scalability: Can run anywhere ‚Äî no GPU or order book needed at first.

    Modularity: All scoring functions are isolated and can later be offloaded to GPU.

    AI-ready data: We log every signal feature, decision, and outcome so future agents can learn, backtest, and optimize kernels or weights automatically.

üéØ Goal of Agents

These ‚Äúagents‚Äù are modular scoring modules that process price tick history in isolated timeframes and emit weighted signals.
They can be combined or evolved into RL/ML modules once GPU acceleration or reinforcement training is added.

Each agent must:

    Take in a tick stream: [slot, price]

    Compute feature(s): delta, cycle, deviation, etc.

    Output a score and tag

    Optionally: store z-score, confidence, and strategy metadata

üìä Tracked Metrics Per Agent

These are all numerically pure, transformable features (z-score/normalized), perfect for future GPU porting or AI modeling:
Feature	Description	Usage
momentum	ŒîP over N ticks	Entry strength
hilbert_phase	Price phase angle from analytic Hilbert transform	Reversal zone detection
fft_band_power	Spectral energy in 0.04‚Äì0.10Hz band	Detect spoof cycles / cyclical pumps
permutation_entropy	Price entropy from ordinal pattern analysis	Trend exhaustion or chaotic motion
fama_gap	(Price - FAMA) / ATR	Trend fade or extension detection
fractal_atr	Hurst-adaptive ATR	Volatility-weighted position sizing
score_weight_matrix	Final score = Œ£ w·µ¢ ¬∑ z·µ¢	Blended signal output
üß¨ Weighting System

Each agent‚Äôs output is tagged and scored. These tags are composed into strategy IDs (e.g., microcap_1m_hilbert_momentum) and logged with the following:

    raw_score

    weighted_score

    strategy_id

    timeframe

    market_cap_tier

    final_decision

These are stored in Arrow2 Parquet, and updated post-trade with PnL feedback using a strategy_weights.json or .parquet reinforcement file.
üöÄ GPU Forward-Compatibility Plan

Because we‚Äôre tracking structured, windowed price transforms:

    All z-score transforms, FFTs, entropy calcs, and vector ops can be ported to GPU kernels.

    Features are stateless (i.e., they only depend on recent price arrays, not external data).

    Kernels can be evolved via AI or meta-learning tools to discover optimal transformations.

This ensures that any AI agent in the future can:

    Pick up this data

    See which strategies worked over thousands of trades

    Write or auto-generate GPU kernels for those signals

    Compress them into low-latency indicator modules (i.e. fast TA scoring agents)

üßæ Required Log Fields (per signal/trade)

Every agent must store:

    strategy_id

    timeframe

    score

    signal_tags

    feature_values: map of indicator ‚Üí z-score

    final_weight

    PnL_after_trade

    priority_fee

    slippage_estimate

    volume_profile_flag (if applicable)

Logged to:

/data/logs/YYYY-MM-DD/signals.parquet
/data/logs/YYYY-MM-DD/trades.parquet

üß† Summary

This bot is not chasing AI hype ‚Äî it‚Äôs building a robust, interpretable system first.
The goal is to collect thousands of normalized, tagged, post-trade outcomes, so any intelligent agent in the future (human or machine) can:

    Learn what signals work

    Design new ones from existing inputs

    Migrate winning signal logic to GPU kernels

    Auto-optimize weights and confidence thresholds

This is how you future-proof trading intelligence.
# Codex Build Instructions (`agents.md`)

## üß† Purpose

This file describes how **Codex (or any AI-assisted dev environment)** should structure feature modules and setup scripts during initial development.

There are no runtime agents. This is not a training loop or self-updating system.

---

## ‚úÖ Goal

When using Codex to build new feature modules (e.g. FFT scoring, Hilbert phase detection), the AI must:

1. Output the Rust code file with the logic
2. Output a matching setup script (PowerShell `.ps1`) if any install or system config is required
3. Log all signals in a structured way (Arrow2-compatible)

---

## üìÇ Expected Outputs from Codex Tasks

### 1. Signal Feature Module
**Example Output File:**

Must include:
- A public `compute_feature()` function
- Return type matching the signal schema
- No runtime scoring logic ‚Äî only math feature generation

### 2. Install Script
If the signal uses any crate not yet installed or system tool (like linking to CUDA or FFTW), also output:
follow an example of to auto find folders and add to path using powershell https://github.com/shetautnetjer/hello-gpu


Should:
- Run `cargo add rustfft`
- Export environment variables if needed
- Optionally add to `src/signals/mod.rs`

### 3. Log Schema
All feature modules must emit a `FeatureRecord`:

```rust
struct FeatureRecord {
  slot: u64,
  price: f64,
  zscore: f64,
  tag: &'static str,
  strategy_id: String,
  timeframe: String,
}
